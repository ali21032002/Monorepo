# سیستم تحلیل چند مدله LangExtract 🤖⚖️

## خلاصه تغییرات

سیستم LangExtract حالا از **تحلیل چند مدله با داوری** پشتیبانی می‌کند. این قابلیت جدید امکان استفاده از چندین مدل AI برای تحلیل دقیق‌تر متون را فراهم می‌کند.

## ویژگی‌های جدید ✨

### 1. تحلیل چند مرحله‌ای
- **مدل اول**: تحلیل اولیه متن
- **مدل دوم**: تحلیل مستقل دوم
- **مدل داور**: بررسی نتایج و ارائه تصمیم نهایی

### 2. حوزه‌های تخصصی
- **عمومی**: متون روزمره و عمومی
- **حقوقی**: اسناد قانونی، قراردادها، احکام دادگاه
- **پزشکی**: پرونده‌های پزشکی، تشخیص‌ها، درمان‌ها
- **پلیسی**: گزارش‌های امنیتی، پرونده‌های جرمی

### 3. تحلیل تعارضات
- شناسایی موجودیت‌های متعارض بین مدل‌ها
- تشخیص روابط مختلف
- محاسبه درصد توافق بین مدل‌ها

## نحوه استفاده 🚀

### API Endpoint جدید

```http
POST /api/multi_extract
Content-Type: application/json

{
  "text": "متن مورد نظر برای تحلیل",
  "language": "fa",
  "domain": "police",
  "model_first": "gemma3:4b",
  "model_second": "llama3:8b", 
  "model_referee": "llama3:8b"
}
```

### پاسخ API

```json
{
  "text": "متن اصلی",
  "language": "fa",
  "domain": "police",
  "first_analysis": {
    "model_name": "gemma3:4b",
    "entities": [...],
    "relationships": [...]
  },
  "second_analysis": {
    "model_name": "llama3:8b", 
    "entities": [...],
    "relationships": [...]
  },
  "final_analysis": {
    "model_name": "llama3:8b",
    "entities": [...],
    "relationships": [...]
  },
  "agreement_score": 0.85,
  "conflicting_entities": ["..."],
  "conflicting_relationships": ["..."]
}
```

### استفاده در کد Python

```python
from langextract import run_multi_model_analysis

result = run_multi_model_analysis(
    text="آقای احمد رضایی در تهران دستگیر شد...",
    language="fa",
    domain="police",
    model_first="gemma3:4b",
    model_second="llama3:8b",
    model_referee="llama3:8b"
)

print(f"Agreement: {result['agreement_score']:.2%}")
print(f"Final entities: {len(result['final_analysis']['entities'])}")
```

## رابط کاربری جدید 🎨

### انتخاب نوع تحلیل
- **تک مدل**: روش سنتی با یک مدل
- **چند مدل (داوری)**: روش جدید با سه مدل

### انتخاب حوزه تخصصی
- عمومی، حقوقی، پزشکی، پلیسی

### نمایش نتایج مرحله‌ای
- نتیجه مدل اول
- نتیجه مدل دوم  
- تصمیم نهایی داور
- تعارضات شناسایی شده
- درصد توافق

## مثال‌های کاربرد 📋

### متن پلیسی
```
در تاریخ ۱۴۰۲/۱۲/۱۵، آقای احمد رضایی در خیابان ولیعصر 
توسط افسر علی محمدی دستگیر شد. متهم به سرقت از فروشگاه 
"دیجی‌کالا" است. شاهد: آقای حسن احمدی
```

**موجودیت‌های شناسایی شده:**
- SUSPECT: احمد رضایی
- OFFICER: علی محمدی  
- WITNESS: حسن احمدی
- CRIME: سرقت
- LOCATION: خیابان ولیعصر
- DATE: ۱۴۰۲/۱۲/۱۵

### متن پزشکی
```
بیمار احمد رضایی با علائم تب و سرفه به بیمارستان مراجعه کرد.
دکتر علی محمدی تشخیص آنفولانزا داد و داروی تامی‌فلو تجویز کرد.
```

**موجودیت‌های شناسایی شده:**
- PATIENT: احمد رضایی
- DOCTOR: علی محمدی
- SYMPTOM: تب، سرفه
- DISEASE: آنفولانزا  
- MEDICATION: تامی‌فلو

## تست سیستم 🧪

برای تست سیستم جدید:

```bash
python test_multi_model.py
```

این اسکریپت:
- تست prompt های تخصصی
- تست تحلیل چند مدله (نیاز به Ollama)
- نمایش نتایج و آمار

## پیش‌نیازها 📋

### مدل‌های پیشنهادی
- `gemma3:4b` - سریع و کارآمد
- `llama3:8b` - دقت بالا
- `qwen2.5:7b` - عملکرد متعادل
- `mistral:7b` - سرعت خوب

### نصب مدل‌ها
```bash
ollama pull gemma3:4b
ollama pull llama3:8b
ollama pull qwen2.5:7b
```

## بهبودهای عملکرد 🚀

### مزایای سیستم چند مدله
1. **دقت بالاتر**: ترکیب نظرات چند مدل
2. **کاهش خطا**: شناسایی و رفع تناقضات
3. **اعتماد بیشتر**: درصد توافق بین مدل‌ها
4. **تخصص حوزه‌ای**: prompt های بهینه شده

### بهینه‌سازی‌ها
- اجرای موازی مدل‌ها (در آینده)
- کش کردن نتایج مشابه
- تنظیم دمای مدل‌ها برای دقت بهتر

## مسیر توسعه آینده 🛣️

- [ ] اجرای موازی مدل‌ها
- [ ] حوزه‌های تخصصی بیشتر (مالی، فنی، ...)
- [ ] تنظیمات پیشرفته داوری
- [ ] گزارش‌های تفصیلی HTML
- [ ] API برای مقایسه مدل‌ها
- [ ] پشتیبانی از مدل‌های محلی بیشتر

---

**نکته**: این سیستم برای تحلیل دقیق متون حساس و مهم طراحی شده است. برای متون ساده، حالت تک مدل کافی است.
